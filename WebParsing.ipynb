{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdaa8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328879b2",
   "metadata": {},
   "source": [
    "## Домашнее задание к лекции \"Основы веб-скрапинга\"\n",
    "Обязательная часть\n",
    "\n",
    "Вам необходимо написать функцию, которая будет основана на поиске по сайту habr.com. Функция в качестве параметра должна принимать список запросов для поиска (например, ['python', 'анализ данных']) и на основе материалов, попавших в результаты поиска по каждому запросу, возвращать датафрейм вида:\n",
    "\n",
    "<дата> - <заголовок> - <ссылка на материал>\n",
    "\n",
    "В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f0effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_habr_articles_with_params(queries):\n",
    "    habr_df  = pd.DataFrame() \n",
    "    URL = 'https://habr.com/ru/search/' \n",
    "    \n",
    "    for query in queries:\n",
    "        params = {\n",
    "            'q': query\n",
    "        }\n",
    "        req = requests.get(url=URL, params=params) \n",
    "        soup = BeautifulSoup(req.text)\n",
    "        \n",
    "        articles = soup.find_all('article', class_='tm-articles-list__item')\n",
    "        for article in articles:\n",
    "            date = article.find('span', class_='tm-article-snippet__datetime-published').find('time').get('datetime')\n",
    "            header = article.find('h2', class_='tm-article-snippet__title').text\n",
    "            link = 'https://habr.com' + article.find('a', class_='tm-article-snippet__title-link').get('href')\n",
    "            \n",
    "            row = {\n",
    "                'date': datetime.strptime(date, '%Y-%m-%dT%H:%M:%S.000Z'),\n",
    "                'header': header,\n",
    "                'link': link\n",
    "            }\n",
    "            habr_df = pd.concat([habr_df, pd.DataFrame([row])])\n",
    "\n",
    "    return habr_df.reset_index(drop=True)\n",
    "    \n",
    "df = get_habr_articles_with_params(['python', 'анализ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db30e499",
   "metadata": {},
   "source": [
    "## Дополнительная часть (необязательная)\n",
    "\n",
    "Функция из обязательной части задания должна быть расширена следующим образом:\n",
    "\n",
    "    кроме списка ключевых слов для поиска необходимо объявить параметр с количеством страниц поисковой выдачи. Т.е. при передаче в функцию аргумента 4 необходимо получить материалы с первых 4 страниц результатов;\n",
    "    в датафрейме должны быть столбцы с полным текстом найденных материалов и количеством лайков:\n",
    "\n",
    "<дата> - <заголовок> - <ссылка на материал> - <текст материала> - <количество лайков>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "939131a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_habr_articles_with_params_count_pages(queries, count_pages=1):\n",
    "    habr_df  = pd.DataFrame()\n",
    "    for page in range(1, count_pages + 1):\n",
    "        URL = f'https://habr.com/ru/search/page{count_pages}'\n",
    "        for query in queries:\n",
    "            params = {\n",
    "                'q': query\n",
    "            }\n",
    "            req = requests.get(url=URL, params=params)\n",
    "            soup = BeautifulSoup(req.text)\n",
    "        \n",
    "            articles = soup.find_all('article', class_='tm-articles-list__item')\n",
    "            for article in articles:\n",
    "                date = article.find('span', class_='tm-article-snippet__datetime-published').find('time').get('datetime')\n",
    "                header = article.find('h2', class_='tm-article-snippet__title').text\n",
    "                link = 'https://habr.com' + article.find('a', class_='tm-article-snippet__title-link').get('href')\n",
    "                count_like = article.find('div', 'tm-votes-meter tm-data-icons__item').find('span').text\n",
    "            \n",
    "                row = {\n",
    "                    'date': datetime.strptime(date, '%Y-%m-%dT%H:%M:%S.000Z'),\n",
    "                    'header': header,\n",
    "                    'link': link,\n",
    "                    'count_like': count_like\n",
    "                }\n",
    "                habr_df = pd.concat([habr_df, pd.DataFrame([row])])\n",
    "                count_pages += 1\n",
    "\n",
    "    return habr_df.reset_index(drop=True)\n",
    "    \n",
    "df = get_habr_articles_with_params_count_pages(['python', 'анализ'], count_pages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7ddfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_description(article_df):\n",
    "    for i, news in enumerate(article_df['link']):\n",
    "        req = requests.get(news)\n",
    "        soup = BeautifulSoup(req.text)\n",
    "        html_text = soup.find_all('p')\n",
    "        description = ''\n",
    "        for item in html_text:\n",
    "            description += item.text\n",
    "        article_df.loc[i, 'description'] = description\n",
    "    return article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4091198",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = add_description(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0b22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
